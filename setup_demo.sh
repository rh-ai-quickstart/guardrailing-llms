#!/bin/bash

# Generated by Cursor

# Guardrailing LLMs Setup Script
# This script automates the installation and verification of the Guardrailing LLMs quickstart

set -e  # Exit on any error

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
PROJECT="guardrails-demo"
WORKSPACE_DIR="${HOME}/workspace"
REPO_URL="https://github.com/rh-ai-quickstart/guardrailing-llms.git"
FORCE_CLEAN_INSTALL=false

# Function to print colored output
print_status() {
    local status=$1
    local message=$2
    case $status in
        "PASS") echo -e "${GREEN}✓ PASS: ${message}${NC}" ;;
        "FAIL") echo -e "${RED}✗ FAIL: ${message}${NC}" ;;
        "WARN") echo -e "${YELLOW}⚠ WARN: ${message}${NC}" ;;
        "INFO") echo -e "${BLUE}ℹ INFO: ${message}${NC}" ;;
    esac
}

# Function to show usage
show_usage() {
    echo "Usage: $0 [OPTIONS]"
    echo ""
    echo "Options:"
    echo "  --force-clean    Force clean installation by deleting existing project"
    echo "  --project NAME   Use custom project name (default: guardrails-demo)"
    echo "  --help           Show this help message"
    echo ""
    echo "Examples:"
    echo "  $0                                    # Normal installation"
    echo "  $0 --force-clean                     # Force clean installation"
    echo "  $0 --project my-guardrails           # Use custom project name"
}

# Function to parse command line arguments
parse_arguments() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            --force-clean)
                FORCE_CLEAN_INSTALL=true
                shift
                ;;
            --project)
                PROJECT="$2"
                shift 2
                ;;
            --help)
                show_usage
                exit 0
                ;;
            *)
                echo "Unknown option: $1"
                show_usage
                exit 1
                ;;
        esac
    done
}

# Function to check if command exists
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# Function to check prerequisites
check_prerequisites() {
    echo -e "\n${BLUE}=== Checking Prerequisites ===${NC}"

    # Check required commands
    local missing_commands=()
    for cmd in oc helm git jq; do
        if ! command_exists "$cmd"; then
            missing_commands+=("$cmd")
        fi
    done

    if [ ${#missing_commands[@]} -gt 0 ]; then
        print_status "FAIL" "Missing required commands: ${missing_commands[*]}"
        echo "Please install the missing commands and try again."
        exit 1
    else
        print_status "PASS" "All required commands are available"
    fi
}

# Function to verify hardware requirements
verify_hardware() {
    echo -e "\n${BLUE}=== Verifying Hardware Requirements ===${NC}"

    # Check GPU availability on worker nodes
    echo "Checking GPU resources..."
    GPU_COUNT=$(oc get nodes -l node-role.kubernetes.io/worker -o jsonpath='{range .items[*]}{.status.allocatable.nvidia\.com/gpu}{"\n"}{end}' | grep -v "^$" | awk '{sum+=$1} END {print sum+0}')
    echo "Total GPU resources: $GPU_COUNT"
    if [ "$GPU_COUNT" -gt 0 ]; then
        print_status "PASS" "GPU resources available"
    else
        print_status "FAIL" "No GPU resources found"
        return 1
    fi

    # Check CPU cores across all nodes
    echo "Checking CPU resources..."
    TOTAL_CPU=$(oc get nodes -o jsonpath='{range .items[*]}{.status.allocatable.cpu}{"\n"}{end}' | sed 's/m//g' | awk '{sum+=$1} END {print int(sum/1000)}')
    echo "Total CPU cores: $TOTAL_CPU"
    if [ "$TOTAL_CPU" -ge 12 ]; then
        print_status "PASS" "Sufficient CPU (12+ cores)"
    elif [ "$TOTAL_CPU" -ge 8 ]; then
        print_status "WARN" "Minimum CPU (8+ cores)"
    else
        print_status "FAIL" "Insufficient CPU (<8 cores)"
        return 1
    fi

    # Check memory across all nodes
    echo "Checking memory resources..."
    TOTAL_MEMORY=$(oc get nodes -o jsonpath='{range .items[*]}{.status.allocatable.memory}{"\n"}{end}' | sed 's/Ki//g' | awk '{sum+=$1} END {print int(sum/1024/1024)}')
    echo "Total memory: ${TOTAL_MEMORY}Gi"
    if [ "$TOTAL_MEMORY" -ge 24 ]; then
        print_status "PASS" "Sufficient memory (24+ Gi)"
    elif [ "$TOTAL_MEMORY" -ge 16 ]; then
        print_status "WARN" "Minimum memory (16+ Gi)"
    else
        print_status "FAIL" "Insufficient memory (<16 Gi)"
        return 1
    fi

    # Check for GPU-enabled nodes
    echo "Checking GPU-enabled nodes..."
    GPU_NODES=$(oc get nodes -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.status.capacity.nvidia\.com/gpu}{"\n"}{end}' | grep -c -v "^\s*$")
    echo "GPU-enabled nodes: $GPU_NODES"
    if [ "$GPU_NODES" -gt 0 ]; then
        print_status "PASS" "GPU-enabled nodes found"
    else
        print_status "FAIL" "No GPU-enabled nodes found"
        return 1
    fi

    # Verify storage classes are available
    echo "Checking storage classes..."
    STORAGE_CLASSES=$(oc get storageclass --no-headers | wc -l)
    echo "Available storage classes: $STORAGE_CLASSES"
    if [ "$STORAGE_CLASSES" -gt 0 ]; then
        print_status "PASS" "Storage classes available"
    else
        print_status "FAIL" "No storage classes found"
        return 1
    fi
}

# Function to verify software requirements
verify_software() {
    echo -e "\n${BLUE}=== Verifying Software Requirements ===${NC}"

    # Check OpenShift cluster version
    echo "Checking OpenShift version..."
    CLUSTER_VERSION=$(oc get clusterversion version -o jsonpath='{.status.desired.version}' 2>/dev/null)
    if [ -z "$CLUSTER_VERSION" ]; then
        # Fallback to oc version if clusterversion is not available
        CLUSTER_VERSION=$(oc version | grep "Server Version" | awk '{print $3}')
    fi
    echo "OpenShift version: $CLUSTER_VERSION"
    if [[ "$CLUSTER_VERSION" =~ ^4\.(1[8-9]|[2-9][0-9])\. ]]; then
        print_status "PASS" "Compatible OpenShift version"
    else
        print_status "WARN" "Version may not be compatible with tested 4.19.9"
    fi

    # Check if Service Mesh is installed
    echo "Checking Service Mesh..."
    SERVICE_MESH=$(oc get csv -n openshift-operators | grep -c -i "servicemesh\|istio")
    echo "Service Mesh operators: $SERVICE_MESH"
    if [ "$SERVICE_MESH" -gt 0 ]; then
        print_status "PASS" "Service Mesh installed"
    else
        print_status "FAIL" "Service Mesh not found"
        return 1
    fi

    # Verify cluster admin permissions
    echo "Checking cluster admin permissions..."
    ADMIN_CHECK=$(oc auth can-i '*' '*' --all-namespaces 2>/dev/null)
    echo "Cluster admin access: $ADMIN_CHECK"
    if [ "$ADMIN_CHECK" = "yes" ]; then
        print_status "PASS" "Cluster admin permissions confirmed"
    else
        print_status "FAIL" "Insufficient permissions - cluster admin required"
        return 1
    fi

    # Check OpenShift cluster health
    echo "Checking cluster health..."
    UNHEALTHY_OPERATORS=$(oc get clusteroperators --no-headers | grep -c -v "True")
    echo "Unhealthy operators: $UNHEALTHY_OPERATORS"
    if [ "$UNHEALTHY_OPERATORS" -eq 0 ]; then
        print_status "PASS" "All cluster operators healthy"
    else
        print_status "WARN" "$UNHEALTHY_OPERATORS operators not in True status"
    fi
}

# Function to verify OpenShift AI and KServe
verify_openshift_ai() {
    echo -e "\n${BLUE}=== Verifying OpenShift AI and KServe ===${NC}"

    # Check if OpenShift AI is installed
    echo "Checking OpenShift AI installation..."
    if oc get csv -n redhat-ods-operator | grep -i "opendatahub\|rhods\|rhoai" >/dev/null; then
        print_status "PASS" "OpenShift AI is installed"
    else
        print_status "FAIL" "OpenShift AI not found"
        return 1
    fi

    # Check if KServe is available
    echo "Checking KServe CRDs..."
    KSERVE_CRDS=$(oc get crd | grep -c -i kserve)
    echo "KServe CRDs found: $KSERVE_CRDS"
    if [ "$KSERVE_CRDS" -gt 0 ]; then
        print_status "PASS" "KServe CRDs available"
    else
        print_status "FAIL" "KServe CRDs not found"
        return 1
    fi

    # Check for KServe components in the cluster
    echo "Checking KServe components..."
    if oc get pods -n redhat-ods-applications | grep -i kserve >/dev/null; then
        print_status "PASS" "KServe components running"

        # Wait for KServe controller to be ready
        echo "Waiting for KServe controller to be ready..."
        wait_for_deployment_ready "redhat-ods-applications" "kserve-controller-manager" 300
    else
        print_status "WARN" "KServe components not found or not running"
    fi

    # Verify the OpenShift AI dashboard is accessible
    echo "Checking OpenShift AI dashboard..."
    if oc get routes -n redhat-ods-applications | grep dashboard >/dev/null; then
        print_status "PASS" "OpenShift AI dashboard accessible"

        # Wait for dashboard pods to be ready
        echo "Waiting for OpenShift AI dashboard to be ready..."
        wait_for_deployment_ready "redhat-ods-applications" "rhods-dashboard" 300
    else
        print_status "WARN" "OpenShift AI dashboard not accessible"
    fi

    # Check if the required operators are running
    echo "Checking required operators..."
    OPERATOR_PODS=$(oc get pods -n redhat-ods-operator | grep -c -E "(rhods|kserve|opendatahub)")
    echo "Operator pods running: $OPERATOR_PODS"
    if [ "$OPERATOR_PODS" -gt 0 ]; then
        print_status "PASS" "Required operators running"

        # Wait for RHODS operator to be ready
        echo "Waiting for RHODS operator to be ready..."
        wait_for_deployment_ready "redhat-ods-operator" "rhods-operator" 300
    else
        print_status "WARN" "Required operators not found or not running"
    fi

    # Verify KServe ServingRuntime CRD exists
    echo "Checking KServe ServingRuntime CRD..."
    if oc get crd servingruntimes.serving.kserve.io >/dev/null 2>&1; then
        print_status "PASS" "KServe ServingRuntime CRD exists"
    else
        print_status "FAIL" "KServe ServingRuntime CRD not found"
        return 1
    fi
}

# Function to wait for project deletion to complete
wait_for_project_deletion() {
    local project_name=$1
    local max_wait_time=300  # 5 minutes
    local wait_time=0

    echo "Checking if project $project_name is being deleted..."

    while [ $wait_time -lt "$max_wait_time" ]; do
        if ! oc get project "$project_name" >/dev/null 2>&1; then
            print_status "PASS" "Project $project_name deletion completed"
            return 0
        fi

        # Check if project is in terminating state
        local project_status
        project_status=$(oc get project "$project_name" -o jsonpath='{.status.phase}' 2>/dev/null)
        if [ "$project_status" = "Terminating" ]; then
            print_status "INFO" "Project $project_name is being deleted, waiting for completion..."
            sleep 10
            wait_time=$((wait_time + 10))
        else
            # Project exists and is not terminating, proceed
            return 0
        fi
    done

    print_status "WARN" "Project $project_name deletion is taking longer than expected, proceeding anyway"
    return 1
}

# Function to install the application
install_application() {
    echo -e "\n${BLUE}=== Installing Guardrailing LLMs ===${NC}"

    # Create workspace directory if it doesn't exist
    if [ ! -d "$WORKSPACE_DIR" ]; then
        mkdir -p "$WORKSPACE_DIR"
        print_status "INFO" "Created workspace directory: $WORKSPACE_DIR"
    fi

    # Clone the repository
    echo "Cloning repository..."
    cd "$WORKSPACE_DIR"
    if [ -d "guardrailing-llms" ]; then
        print_status "INFO" "Repository already exists, updating..."
        cd guardrailing-llms
        git pull
    else
        git clone "$REPO_URL"
        cd guardrailing-llms
        print_status "PASS" "Repository cloned successfully"
    fi

    # Handle OpenShift project creation/deletion
    echo "Handling OpenShift project..."
    if oc get project "$PROJECT" >/dev/null 2>&1; then
        local project_status
        project_status=$(oc get project "$PROJECT" -o jsonpath='{.status.phase}' 2>/dev/null)
        if [ "$project_status" = "Terminating" ]; then
            print_status "INFO" "Project $PROJECT is being deleted, waiting for completion..."
            wait_for_project_deletion "$PROJECT"
            if wait_for_project_deletion "$PROJECT"; then
                print_status "INFO" "Project deletion completed, creating new project..."
                oc new-project "$PROJECT"
                print_status "PASS" "Project $PROJECT created successfully"
            else
                print_status "WARN" "Project deletion still in progress, attempting to create anyway..."
                oc new-project "$PROJECT" 2>/dev/null || {
                    print_status "WARN" "Failed to create project, it may still be deleting. Waiting longer..."
                    sleep 30
                    oc new-project "$PROJECT"
                }
                print_status "PASS" "Project $PROJECT created successfully"
            fi
        else
            if [ "$FORCE_CLEAN_INSTALL" = "true" ]; then
                print_status "INFO" "Force clean installation requested, deleting existing project..."
                oc delete project "$PROJECT" --wait=false
                print_status "INFO" "Waiting for project deletion to complete..."
                wait_for_project_deletion "$PROJECT"
                print_status "INFO" "Creating fresh project..."
                oc new-project "$PROJECT"
                print_status "PASS" "Project $PROJECT created successfully"
            else
                print_status "INFO" "Project $PROJECT already exists and is active"
                oc project "$PROJECT"

                # Check if Helm release already exists
                if helm list -n "$PROJECT" | grep -q "guardrailing-llms"; then
                    print_status "INFO" "Existing Helm release found, uninstalling previous deployment..."
                    helm uninstall guardrailing-llms -n "$PROJECT" || {
                        print_status "WARN" "Failed to uninstall existing Helm release, continuing with installation..."
                    }
                    # Wait a moment for resources to be cleaned up
                    sleep 10
                fi
            fi
        fi
    else
        oc new-project "$PROJECT"
        print_status "PASS" "Project $PROJECT created successfully"
    fi

    # Install with Helm
    echo "Installing with Helm..."
    if helm install \
        guardrailing-llms \
        helm/ \
        --namespace "$PROJECT" \
        --set workbench.image="image-registry.openshift-image-registry.svc:5000/redhat-ods-applications/s2i-minimal-notebook:2025.1"; then
        print_status "PASS" "Helm installation completed successfully"
    else
        print_status "FAIL" "Helm installation failed"
        return 1
    fi

    # Wait for core components to be ready
    echo -e "\n${BLUE}=== Waiting for Core Components ===${NC}"

    # Wait for workbench to be ready
    echo "Waiting for workbench to be ready (this may take a few minutes)..."
    wait_for_deployment_ready "$PROJECT" "guardrails-workbench" 600  # 10 minutes for workbench initialization

    # Wait for orchestrator to be ready
    echo "Waiting for orchestrator to be ready (this may take a few minutes)..."
    wait_for_deployment_ready "$PROJECT" "gorch-sample" 600  # 10 minutes for orchestrator initialization

    # Wait for LLM predictor to be ready (this may take longer due to GPU requirements)
    echo "Waiting for LLM predictor to be ready (this may take several minutes for GPU initialization)..."
    wait_for_deployment_ready "$PROJECT" "llama-32-3b-instruct-predictor" 900  # 15 minutes for GPU workloads

    # Wait for detector services to be ready (extended timeouts for AI model loading)
    echo "Waiting for detector services to be ready (this may take several minutes for AI model loading)..."
    wait_for_deployment_ready "$PROJECT" "gibberish-detector-predictor" 600  # 10 minutes
    wait_for_deployment_ready "$PROJECT" "prompt-injection-detector-predictor" 600  # 10 minutes
    wait_for_deployment_ready "$PROJECT" "ibm-hate-and-profanity-detector-predictor" 600  # 10 minutes
}

# Function to wait for specific pods to be ready
wait_for_pods_ready() {
    local namespace=$1
    local selector=$2
    local timeout=${3:-600}  # Default 10 minutes
    local description=${4:-"pods"}

    echo "Waiting for $description to be ready (timeout: ${timeout}s)..."

    if oc wait --for=condition=Ready pod -l "$selector" --timeout="${timeout}"s -n "$namespace" 2>/dev/null; then
        print_status "PASS" "$description are ready"
        return 0
    else
        print_status "WARN" "$description are not ready within timeout"
        return 1
    fi
}

# Function to wait for all pods in namespace to be ready
wait_for_all_pods_ready() {
    local namespace=$1
    local timeout=${2:-600}  # Default 10 minutes

    echo "Waiting for all pods in namespace $namespace to be ready..."

    # Wait for pods to be created first
    local retry_count=0
    local max_retries=30
    while [ $retry_count -lt $max_retries ]; do
        local pod_count
        pod_count=$(oc get pods -n "$namespace" --no-headers 2>/dev/null | wc -l)
        if [ "$pod_count" -gt 0 ]; then
            break
        fi
        echo "Waiting for pods to be created... ($((retry_count + 1))/$max_retries)"
        sleep 10
        retry_count=$((retry_count + 1))
    done

    if [ $retry_count -eq $max_retries ]; then
        print_status "WARN" "No pods found in namespace $namespace"
        return 1
    fi

    # Wait for pods to be ready
    local not_ready_count=0
    local max_wait_time=$timeout
    local wait_time=0

    while [ $wait_time -lt "$max_wait_time" ]; do
        not_ready_count=$(oc get pods -n "$namespace" --no-headers | grep -c -v "Completed" | grep -c -v "Running")

        if [ "$not_ready_count" -eq 0 ]; then
            print_status "PASS" "All pods in $namespace are ready"
            return 0
        fi

        echo "Waiting for $not_ready_count pods to be ready... (${wait_time}s/${max_wait_time}s)"
        sleep 10
        wait_time=$((wait_time + 10))
    done

    print_status "WARN" "$not_ready_count pods are still not ready after ${max_wait_time}s"
    return 1
}

# Function to wait for specific deployment to be ready
wait_for_deployment_ready() {
    local namespace=$1
    local deployment_name=$2
    local timeout=${3:-600}  # Default 10 minutes

    echo "Waiting for deployment $deployment_name to be ready..."

    if oc wait --for=condition=Available deployment/"$deployment_name" --timeout="${timeout}"s -n "$namespace" 2>/dev/null; then
        print_status "PASS" "Deployment $deployment_name is ready"
        return 0
    else
        print_status "WARN" "Deployment $deployment_name is not ready within timeout"
        return 1
    fi
}

# Function to wait for pods to be ready (legacy function for backward compatibility)
wait_for_pods() {
    echo -e "\n${BLUE}=== Waiting for Pods to be Ready ===${NC}"

    # Wait for all pods in the project to be ready
    wait_for_all_pods_ready "$PROJECT" 600

    echo "Current pod status:"
    oc get pod -n "$PROJECT"

    # Check if all pods are running
    NOT_READY=$(oc get pod -n "$PROJECT" | grep -c -v "Completed" | grep -c -v "Running")
    if [ "$NOT_READY" -eq 0 ]; then
        print_status "PASS" "All pods are running"
    else
        print_status "WARN" "$NOT_READY pods are not ready yet"
    fi
}

# Function to check detailed pod health
check_pod_health() {
    local namespace=$1
    local pod_name=$2
    local description=$3

    echo "Checking $description pod health..."

    # Get pod status
    local pod_status
    pod_status=$(oc get pod -n "$namespace" "$pod_name" -o jsonpath='{.status.phase}' 2>/dev/null)
    if [ "$pod_status" = "Running" ]; then
        print_status "PASS" "$description pod is running"
    else
        print_status "WARN" "$description pod status: $pod_status"
        return 1
    fi

    # Check container readiness
    local ready_containers
    ready_containers=$(oc get pod -n "$namespace" "$pod_name" -o jsonpath='{.status.containerStatuses[*].ready}' 2>/dev/null | grep -c -o "true")
    local total_containers
    total_containers=$(oc get pod -n "$namespace" "$pod_name" -o jsonpath='{.status.containerStatuses[*].name}' 2>/dev/null | wc -w)

    if [ "$ready_containers" -eq "$total_containers" ] && [ "$total_containers" -gt 0 ]; then
        print_status "PASS" "$description: $ready_containers/$total_containers containers ready"
    else
        print_status "WARN" "$description: $ready_containers/$total_containers containers ready"
    fi

    # Check restart count
    local restart_count
    restart_count=$(oc get pod -n "$namespace" "$pod_name" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null)
    if [ "$restart_count" -eq 0 ]; then
        print_status "PASS" "$description: No restarts"
    else
        print_status "WARN" "$description: $restart_count restarts"
    fi
}

# Function to check application logs
check_application_logs() {
    local namespace=$1
    local pod_name=$2
    local container_name=$3
    local description=$4
    local success_pattern=$5

    echo "Checking $description application logs..."

    if [ -n "$container_name" ]; then
        local logs
        logs=$(oc logs -n "$namespace" "$pod_name" -c "$container_name" --tail=10 2>/dev/null)
    else
        local logs
        logs=$(oc logs -n "$namespace" "$pod_name" --tail=10 2>/dev/null)
    fi

    if [ -n "$logs" ]; then
        if echo "$logs" | grep -q "$success_pattern"; then
            print_status "PASS" "$description: Application logs show successful startup"
        else
            print_status "WARN" "$description: Application may not be fully ready"
            echo "Recent logs:"
            echo "$logs" | tail -3
        fi
    else
        print_status "WARN" "$description: No logs available"
    fi
}

# Function to verify specific services
verify_services() {
    local namespace=$1
    local service_pattern=$2
    local description=$3

    echo "Checking $description services..."

    local services
    services=$(oc get svc -n "$namespace" | grep -c -E "$service_pattern")
    if [ "$services" -gt 0 ]; then
        print_status "PASS" "$description: $services services found"

        # Show service details
        echo "Service details:"
        oc get svc -n "$namespace" | grep -E "$service_pattern" | while read -r line; do
            echo "  $line"
        done
    else
        print_status "WARN" "$description: No services found"
    fi
}

# Function to verify installation
verify_installation() {
    echo -e "\n${BLUE}=== Verifying Installation ===${NC}"

    # Wait for all pods to be ready before verification
    echo "Waiting for all application pods to be ready..."
    wait_for_all_pods_ready "$PROJECT" 600

    # Check all pods are ready
    echo "Checking pod status..."
    NOT_READY=$(oc get pod -n "$PROJECT" | grep -c -v "Completed" | grep -c -v "Running")
    if [ "$NOT_READY" -eq 0 ]; then
        print_status "PASS" "All pods are running"
    else
        print_status "WARN" "$NOT_READY pods are not ready"
    fi

    # Verify Notebook resource exists
    echo "Checking Notebook resource..."
    if oc get notebook -n "$PROJECT" >/dev/null 2>&1; then
        print_status "PASS" "Notebook resource exists"
    else
        print_status "WARN" "Notebook resource not found"
    fi

    # Check Helm release status
    echo "Checking Helm release status..."
    if helm status guardrailing-llms -n "$PROJECT" >/dev/null 2>&1; then
        print_status "PASS" "Helm release is deployed"
    else
        print_status "FAIL" "Helm release not found"
        return 1
    fi

    # Verify detector services are running
    echo "Checking detector services..."
    DETECTOR_PODS=$(oc get pod -n "$PROJECT" | grep -c -E "(detector|predictor|gorch|llama|workbench)")
    echo "Detector service pods: $DETECTOR_PODS"
    if [ "$DETECTOR_PODS" -gt 0 ]; then
        print_status "PASS" "Detector services are running"

        # Wait for specific detector services to be ready
        echo "Waiting for detector services to be ready (extended timeout for AI model loading)..."
        wait_for_pods_ready "$PROJECT" "app=isvc.gibberish-detector-predictor" 600 "Gibberish detector"
        wait_for_pods_ready "$PROJECT" "app=isvc.prompt-injection-detector-predictor" 600 "Prompt injection detector"
        wait_for_pods_ready "$PROJECT" "app=isvc.ibm-hate-and-profanity-detector-predictor" 600 "Hate/profanity detector"

        # Detailed health checks for each detector
        echo -e "\n${BLUE}=== Detailed Detector Health Checks ===${NC}"

        # Gibberish detector detailed check
        GIBBERISH_POD=$(oc get pod -n "$PROJECT" -l app=isvc.gibberish-detector-predictor -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)
        if [ -n "$GIBBERISH_POD" ]; then
            check_pod_health "$PROJECT" "$GIBBERISH_POD" "Gibberish detector"
            check_application_logs "$PROJECT" "$GIBBERISH_POD" "kserve-container" "Gibberish detector" "Application startup complete"
        else
            print_status "WARN" "Gibberish detector pod not found"
        fi

        # Prompt injection detector detailed check
        PROMPT_INJECTION_POD=$(oc get pod -n "$PROJECT" -l app=isvc.prompt-injection-detector-predictor -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)
        if [ -n "$PROMPT_INJECTION_POD" ]; then
            check_pod_health "$PROJECT" "$PROMPT_INJECTION_POD" "Prompt injection detector"
            check_application_logs "$PROJECT" "$PROMPT_INJECTION_POD" "kserve-container" "Prompt injection detector" "Application startup complete"
        else
            print_status "WARN" "Prompt injection detector pod not found"
        fi

        # Hate/profanity detector detailed check
        HATE_PROFANITY_POD=$(oc get pod -n "$PROJECT" -l app=isvc.ibm-hate-and-profanity-detector-predictor -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)
        if [ -n "$HATE_PROFANITY_POD" ]; then
            check_pod_health "$PROJECT" "$HATE_PROFANITY_POD" "Hate/profanity detector"
            check_application_logs "$PROJECT" "$HATE_PROFANITY_POD" "kserve-container" "Hate/profanity detector" "Application startup complete"
        else
            print_status "WARN" "Hate/profanity detector pod not found"
        fi
    else
        print_status "WARN" "Detector services not found"
    fi

    # Verify services are accessible
    echo "Checking service accessibility..."
    SERVICES=$(oc get svc -n "$PROJECT" | grep -c -E "(detector|gorch|llama)")
    echo "Available services: $SERVICES"
    if [ "$SERVICES" -gt 0 ]; then
        print_status "PASS" "Services are accessible"

        # Detailed service verification
        echo -e "\n${BLUE}=== Detailed Service Verification ===${NC}"
        verify_services "$PROJECT" "gibberish-detector" "Gibberish detector"
        verify_services "$PROJECT" "prompt-injection-detector" "Prompt injection detector"
        verify_services "$PROJECT" "hate-and-profanity-detector" "Hate/profanity detector"
        verify_services "$PROJECT" "gorch-sample" "Orchestrator"
        verify_services "$PROJECT" "llama-32-3b-instruct" "LLM predictor"
    else
        print_status "WARN" "Services not found"
    fi

    # Verify orchestrator service
    echo "Checking orchestrator service..."
    if oc get svc gorch-sample-service -n "$PROJECT" >/dev/null 2>&1; then
        ORCHESTRATOR_IP=$(oc get svc gorch-sample-service -n "$PROJECT" -o jsonpath='{.spec.clusterIP}')
        echo "Orchestrator service IP: $ORCHESTRATOR_IP"
        print_status "PASS" "Orchestrator service is accessible"

        # Wait for orchestrator pods to be ready
        echo "Waiting for orchestrator to be ready (extended timeout)..."
        wait_for_pods_ready "$PROJECT" "app=gorch-sample" 600 "Orchestrator"

        # Detailed orchestrator health check
        ORCHESTRATOR_POD=$(oc get pod -n "$PROJECT" -l app=gorch-sample -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)
        if [ -n "$ORCHESTRATOR_POD" ]; then
            echo -e "\n${BLUE}=== Orchestrator Health Check ===${NC}"
            check_pod_health "$PROJECT" "$ORCHESTRATOR_POD" "Orchestrator"
            check_application_logs "$PROJECT" "$ORCHESTRATOR_POD" "" "Orchestrator" "started"
        else
            print_status "WARN" "Orchestrator pod not found"
        fi
    else
        print_status "WARN" "Orchestrator service not found"
    fi

    # Verify LLM predictor and workbench
    echo -e "\n${BLUE}=== LLM Predictor and Workbench Health Checks ===${NC}"

    # LLM predictor health check
    LLM_POD=$(oc get pod -n "$PROJECT" -l app=isvc.llama-32-3b-instruct-predictor -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)
    if [ -n "$LLM_POD" ]; then
        check_pod_health "$PROJECT" "$LLM_POD" "LLM predictor"
        check_application_logs "$PROJECT" "$LLM_POD" "kserve-container" "LLM predictor" "Application startup complete"
    else
        print_status "WARN" "LLM predictor pod not found"
    fi

    # Workbench health check
    WORKBENCH_POD=$(oc get pod -n "$PROJECT" -l statefulset=guardrails-workbench -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)
    if [ -n "$WORKBENCH_POD" ]; then
        check_pod_health "$PROJECT" "$WORKBENCH_POD" "Workbench"
        check_application_logs "$PROJECT" "$WORKBENCH_POD" "jupyter" "Workbench" "Jupyter"
    else
        print_status "WARN" "Workbench pod not found"
    fi

    # Final comprehensive health summary
    echo -e "\n${BLUE}=== Final Health Summary ===${NC}"
    echo "All components status:"
    oc get pods -n "$PROJECT" | grep -E "(detector|predictor|gorch|llama|workbench)" | while read -r line; do
        echo "  $line"
    done

    echo ""
    echo "Service endpoints:"
    oc get svc -n "$PROJECT" | grep -E "(detector|gorch|llama)" | while read -r line; do
        echo "  $line"
    done
}

# Function to get dashboard URL
get_dashboard_url() {
    echo -e "\n${BLUE}=== OpenShift AI Dashboard ===${NC}"

    DASHBOARD_URL=$(oc get routes rhods-dashboard -n redhat-ods-applications -o jsonpath='{.spec.host}' 2>/dev/null)
    if [ -n "$DASHBOARD_URL" ]; then
        echo "OpenShift AI Dashboard URL: https://$DASHBOARD_URL"
        print_status "INFO" "Dashboard accessible at: https://$DASHBOARD_URL"
        print_status "INFO" "Navigate to: Data Science Projects → $PROJECT → guardrails-workbench"
        print_status "INFO" "Access demo notebook: assets/healthcare-guardrails.ipynb"
    else
        print_status "WARN" "Dashboard URL not found"
    fi
}

# Function to show final summary
show_summary() {
    echo -e "\n${BLUE}=== Installation Summary ===${NC}"
    echo "The Guardrailing LLMs installation provides:"
    echo "• Llama 3.2 3B Instruct model with GPU acceleration"
    echo "• Multiple AI safety detectors (gibberish, prompt injection, hate/profanity)"
    echo "• TrustyAI GuardrailsOrchestrator for coordinating safety checks"
    echo "• Jupyter workbench with healthcare demo notebook"
    echo ""
    print_status "INFO" "Installation completed! Check the dashboard URL above to access the demo."
}

# Main execution
main() {
    # Parse command line arguments
    parse_arguments "$@"

    echo -e "${BLUE}Guardrailing LLMs Setup Script${NC}"
    echo "=========================================="
    echo "Project: $PROJECT"
    if [ "$FORCE_CLEAN_INSTALL" = "true" ]; then
        echo "Mode: Force Clean Installation"
    else
        echo "Mode: Standard Installation"
    fi
    echo ""

    # Check prerequisites
    check_prerequisites

    # Verify hardware requirements
    if ! verify_hardware; then
        print_status "FAIL" "Hardware requirements not met. Please check your cluster configuration."
        exit 1
    fi

    # Verify software requirements
    if ! verify_software; then
        print_status "FAIL" "Software requirements not met. Please install required components."
        exit 1
    fi

    # Verify OpenShift AI and KServe
    if ! verify_openshift_ai; then
        print_status "FAIL" "OpenShift AI or KServe requirements not met. Please install required components."
        exit 1
    fi

    # Install the application
    if ! install_application; then
        print_status "FAIL" "Application installation failed."
        exit 1
    fi

    # Wait for pods to be ready
    wait_for_pods

    # Verify installation
    verify_installation

    # Get dashboard URL
    get_dashboard_url

    # Show final summary
    show_summary
}

# Run main function
main "$@"
