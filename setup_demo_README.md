<!-- Generated by Cursor -->

# Complete Guardrailing LLMs Setup Guide

## Prerequisites Verification

### 1. Verify hardware requirements

#### Check GPU availability on worker nodes

```bash
GPU_COUNT=$(oc get nodes -l node-role.kubernetes.io/worker \
  -o jsonpath='{range .items[*]}{.status.allocatable.nvidia\.com/gpu}{"\n"}{end}' \
  | grep -v "^$" | awk '{sum+=$1} END {print sum+0}')
echo "Total GPU resources: $GPU_COUNT"
if [ "$GPU_COUNT" -gt 0 ]; then
  echo "✓ PASS: GPU resources available"
else
  echo "✗ FAIL: No GPU resources found"
fi
```

#### Check CPU cores across all nodes

```bash
TOTAL_CPU=$(oc get nodes -o jsonpath='{range .items[*]}{.status.allocatable.cpu}{"\n"}{end}' \
  | sed 's/m//g' | awk '{sum+=$1} END {print int(sum/1000)}')
echo "Total CPU cores: $TOTAL_CPU"
if [ "$TOTAL_CPU" -ge 12 ]; then
  echo "✓ PASS: Sufficient CPU (12+ cores)"
elif [ "$TOTAL_CPU" -ge 8 ]; then
  echo "⚠ WARN: Minimum CPU (8+ cores)"
else
  echo "✗ FAIL: Insufficient CPU (<8 cores)"
fi
```

#### Check memory across all nodes

```bash
TOTAL_MEMORY=$(oc get nodes -o jsonpath='{range .items[*]}{.status.allocatable.memory}{"\n"}{end}' \
  | sed 's/Ki//g' | awk '{sum+=$1} END {print int(sum/1024/1024)}')
echo "Total memory: ${TOTAL_MEMORY}Gi"
if [ "$TOTAL_MEMORY" -ge 24 ]; then
  echo "✓ PASS: Sufficient memory (24+ Gi)"
elif [ "$TOTAL_MEMORY" -ge 16 ]; then
  echo "⚠ WARN: Minimum memory (16+ Gi)"
else
  echo "✗ FAIL: Insufficient memory (<16 Gi)"
fi
```

#### Check for GPU-enabled nodes

```bash
GPU_NODES=$(oc get nodes -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.status.capacity.nvidia\.com/gpu}{"\n"}{end}' \
  | grep -v "^\s*$" | wc -l)
echo "GPU-enabled nodes: $GPU_NODES"
if [ "$GPU_NODES" -gt 0 ]; then
  echo "✓ PASS: GPU-enabled nodes found"
else
  echo "✗ FAIL: No GPU-enabled nodes found"
fi
```

#### Verify storage classes are available

```bash
STORAGE_CLASSES=$(oc get storageclass --no-headers | wc -l)
echo "Available storage classes: $STORAGE_CLASSES"
if [ "$STORAGE_CLASSES" -gt 0 ]; then
  echo "✓ PASS: Storage classes available"
else
  echo "✗ FAIL: No storage classes found"
fi
```

### 2. Verify software requirements

#### Check OpenShift cluster version

```bash
CLUSTER_VERSION=$(oc version -o json | jq -r '.serverVersion.gitVersion' | sed 's/v//')
echo "OpenShift version: $CLUSTER_VERSION"
if [[ "$CLUSTER_VERSION" =~ ^4\.(1[8-9]|[2-9][0-9])\. ]]; then
  echo "✓ PASS: Compatible OpenShift version"
else
  echo "⚠ WARN: Version may not be compatible with tested 4.19.9"
fi
```

#### Check if Service Mesh is installed

```bash
SERVICE_MESH=$(oc get csv -n openshift-operators | grep -i "servicemesh\|istio" | wc -l)
echo "Service Mesh operators: $SERVICE_MESH"
if [ "$SERVICE_MESH" -gt 0 ]; then
  echo "✓ PASS: Service Mesh installed"
else
  echo "✗ FAIL: Service Mesh not found"
fi
```

#### Verify cluster admin permissions

```bash
ADMIN_CHECK=$(oc auth can-i '*' '*' --all-namespaces 2>/dev/null)
echo "Cluster admin access: $ADMIN_CHECK"
if [ "$ADMIN_CHECK" = "yes" ]; then
  echo "✓ PASS: Cluster admin permissions confirmed"
else
  echo "✗ FAIL: Insufficient permissions - cluster admin required"
fi
```

#### Check OpenShift cluster health

```bash
UNHEALTHY_OPERATORS=$(oc get clusteroperators --no-headers | grep -v "True" | wc -l)
echo "Unhealthy operators: $UNHEALTHY_OPERATORS"
if [ "$UNHEALTHY_OPERATORS" -eq 0 ]; then
  echo "✓ PASS: All cluster operators healthy"
else
  echo "⚠ WARN: $UNHEALTHY_OPERATORS operators not in True status"
fi
```

### 3. Verify OpenShift AI and KServe are enabled

#### Check if OpenShift AI is installed

```bash
oc get csv -n redhat-ods-operator | grep -i "opendatahub\|rhods\|rhoai"
```

Expected output:

```
rhods-operator.2.22.1 Red Hat OpenShift AI 2.22.1 rhods-operator.2.22.0 Succeeded
```

#### Check if KServe is available

```bash
oc get crd | grep -i kserve
```

Expected output:

```
clusterlocalmodels.serving.kserve.io 2025-02-12T16:59:21Z
clusterstoragecontainers.serving.kserve.io 2025-02-12T16:59:21Z
inferencegraphs.serving.kserve.io 2025-04-22T06:03:32Z
inferenceservices.serving.kserve.io 2025-04-22T06:03:28Z
kserves.components.platform.opendatahub.io 2025-04-25T17:18:00Z
localmodelnodegroups.serving.kserve.io 2025-02-12T16:59:21Z
predictors.serving.kserve.io 2025-02-12T16:58:02Z
servingruntimes.serving.kserve.io 2025-04-22T06:03:29Z
trainedmodels.serving.kserve.io 2025-02-12T16:59:21Z
```

#### Check for KServe components in the cluster

```bash
oc get pods -n redhat-ods-applications | grep -i kserve
```

Expected output:

```
kserve-controller-manager-587df4895f-dcmf2 1/1 Running 2 (2d20h ago) 6d6h
```

#### Verify the OpenShift AI dashboard is accessible

```bash
oc get routes -n redhat-ods-applications | grep dashboard
```

Expected output:

```
rhods-dashboard rhods-dashboard-redhat-ods-applications.apps.ods-qe-psi-14.osp.rh-ods.com rhods-dashboard 8443 reencrypt/Redirect None
```

#### Check if the required operators are running

```bash
oc get pods -n redhat-ods-operator | grep -E "(rhods|kserve|opendatahub)"
```

Expected output:

```
rhods-operator-6f9c9c479f-jbwg9 1/1 Running 0 6d6h
rhods-operator-6f9c9c479f-spfg6 1/1 Running 0 6d6h
rhods-operator-6f9c9c479f-v5jv6 1/1 Running 0 6d6h
```

#### Verify KServe ServingRuntime CRD exists

```bash
oc get crd servingruntimes.serving.kserve.io
```

Expected output:

```
NAME CREATED AT
servingruntimes.serving.kserve.io 2025-04-22T06:03:29Z
```

## Installation Steps

### 4. Clone the repository

```bash
cd ${HOME}/workspace
git clone https://github.com/rh-ai-quickstart/guardrailing-llms.git
cd guardrailing-llms
```

### 5. Create OpenShift project

```bash
PROJECT="guardrails-demo"
oc new-project "${PROJECT}"
```

Expected output:

```
Now using project "guardrails-demo" on server "https://api.ods-qe-psi-14.osp.rh-ods.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=registry.k8s.io/e2e-test-images/agnhost:2.43 -- /agnhost serv
```

### 6. Install with Helm (with correct image)

```bash
helm install \
  guardrailing-llms \
  helm/ \
  --namespace "${PROJECT}" \
  --set workbench.image="image-registry.openshift-image-registry.svc:5000/redhat-ods-applications/s2i-minimal-notebook:2025.1"
```

Expected output:

```
NAME: guardrailing-llms
LAST DEPLOYED: Tue Sep 9 12:53:46 2025
NAMESPACE: guardrails-demo
STATUS: deployed
REVISION: 1
TEST SUITE: None
```

### 7. Wait for pods to be running

```bash
oc get pod -n "${PROJECT}"
```

Expected output:

```
NAME READY STATUS RESTARTS AGE
gibberish-detector-predictor-d75db9f84-kzz2w 0/2 PodInitializing 0 54s
gorch-sample-5f579bf8cd-hxjmd 3/3 Running 0 56s
guardrails-workbench-0 2/2 Running 0 55s
guardrails-workbench-clone-repo-s25fd 0/1 Completed 0 56s
ibm-hate-and-profanity-detector-predictor-5f955bd6fc-5ddv4 0/2 PodInitializing 0 55s
llama-32-3b-instruct-predictor-7c5d564946-fl5x7 0/2 Pending 0 54s
prompt-injection-detector-predictor-6ffc8b666c-chd86 0/2 PodInitializing 0 54s
```

### 8. Get OpenShift AI Dashboard URL

```bash
oc get routes rhods-dashboard -n redhat-ods-applications
```

Expected output:

```
NAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD
rhods-dashboard rhods-dashboard-redhat-ods-applications.apps.ods-qe-psi-14.osp.rh-ods.com rhods-dashboard 8443 reencrypt/Redirect None
```

## Verification Steps

### 9. Verify all components are running

#### Check all pods are ready

```bash
oc get pod -n "${PROJECT}" | grep -v "Completed" | grep -v "Running" | wc -l
```

Should return 0 (no non-running pods)

#### Verify Notebook resource exists

```bash
oc get notebook -n ${PROJECT}
```

#### Check Helm release status

```bash
helm status guardrailing-llms -n ${PROJECT}
```

### 10. Verify notebook prerequisites

#### 10.1 Verify the guardrailing-llms Helm chart is deployed

```bash
helm list -n ${PROJECT}
```

#### 10.2 Verify all detector services are running

```bash
oc get pod -n ${PROJECT} | grep -E "(detector|predictor|gorch|llama|workbench)"
```

#### 10.3 Verify specific detector services are accessible

```bash
oc get svc -n ${PROJECT} | grep -E "(detector|gorch|llama)"
```

#### 10.4 Verify the orchestrator service is accessible (key requirement for the notebook)

```bash
oc get svc gorch-sample-service -n ${PROJECT} -o jsonpath='{.spec.clusterIP}' && echo
```

### 11. Access the demo

1. Open the dashboard: Use the URL from step 8
2. Navigate to project: Data Science Projects → guardrails-demo
3. Open workbench: Click on guardrails-workbench
4. Access demo notebook: Navigate to assets/healthcare-guardrails.ipynb

## Troubleshooting (if needed)

- If workbench has image issues:
- If Helm release is stuck:

## Final Verification

### 12. Confirm complete installation

Expected final state: All 6 main components running (2/2 or 3/3 Ready), workbench accessible, dashboard URL available.

The installation provides a complete AI safety framework with:

- Llama 3.2 3B Instruct model with GPU acceleration
- Multiple AI safety detectors (gibberish, prompt injection, hate/profanity)
- TrustyAI GuardrailsOrchestrator for coordinating safety checks
- Jupyter workbench with healthcare demo notebook
